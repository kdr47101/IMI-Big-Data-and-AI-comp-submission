{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 01:09:37,669 - ERROR - File not found: mnt\\data\\abm.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "mnt\\data\\abm.csv not found.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 222\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    221\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 222\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    224\u001b[0m \u001b[38;5;66;03m# Load raw KYC and industry codes data\u001b[39;00m\n\u001b[0;32m    225\u001b[0m kyc_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(RAW_DATA_DIR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mkyc.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: mnt\\data\\abm.csv not found."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import logging\n",
    "import pandas as pd\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Define input and output directories relative to the project root\n",
    "RAW_DATA_DIR = os.path.join(\"mnt\", \"data\")\n",
    "CLEAN_OUTPUT_DIR = os.path.join(\"mnt\", \"output\", \"clean\")\n",
    "\n",
    "# Ensure the cleaned output directory exists\n",
    "os.makedirs(CLEAN_OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "def file_exists(filepath):\n",
    "    if not os.path.exists(filepath):\n",
    "        logging.error(f\"File not found: {filepath}\")\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def clean_transactions(df, date_cols=['transaction_date'], numeric_cols=['amount_cad']):\n",
    "    \"\"\"\n",
    "    Cleans a transaction DataFrame by:\n",
    "      - Dropping duplicate rows\n",
    "      - Stripping extra whitespace from string columns\n",
    "      - Converting date columns to datetime\n",
    "      - Combining 'transaction_date' and 'transaction_time' into a new datetime column (if both exist)\n",
    "      - Converting specified numeric columns to numeric types\n",
    "      - Standardizing 'debit_credit' to lowercase\n",
    "      - Standardizing geographic columns ('country', 'province', 'city') to uppercase\n",
    "      - Dropping rows missing 'customer_id'\n",
    "    \"\"\"\n",
    "    initial_rows = len(df)\n",
    "    df = df.copy()\n",
    "\n",
    "    try:\n",
    "        df.drop_duplicates(inplace=True)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error dropping duplicates: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Strip extra whitespace from all object-type columns\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df[col] = df[col].str.strip()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error stripping whitespace: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Convert date columns to datetime\n",
    "        for col in date_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_datetime(df[col], errors='coerce')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting date columns: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Combine 'transaction_date' and 'transaction_time' if available\n",
    "        if 'transaction_date' in df.columns and 'transaction_time' in df.columns:\n",
    "            df['transaction_time'] = df['transaction_time'].fillna(\"00:00:00\")\n",
    "            df['transaction_datetime'] = pd.to_datetime(\n",
    "                df['transaction_date'].dt.strftime('%Y-%m-%d') + ' ' + df['transaction_time'],\n",
    "                errors='coerce'\n",
    "            )\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error combining date and time: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Convert specified numeric columns to numeric types\n",
    "        for col in numeric_cols:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting numeric columns: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Standardize the 'debit_credit' column to lowercase if present\n",
    "        if 'debit_credit' in df.columns:\n",
    "            df['debit_credit'] = df['debit_credit'].str.lower()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error standardizing 'debit_credit': {e}\")\n",
    "\n",
    "    try:\n",
    "        # Standardize geographic columns to uppercase\n",
    "        for col in ['country', 'province', 'city']:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].str.upper()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error standardizing geographic columns: {e}\")\n",
    "\n",
    "    try:\n",
    "        # Drop rows missing 'customer_id'\n",
    "        if 'customer_id' in df.columns:\n",
    "            df.dropna(subset=['customer_id'], inplace=True)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error dropping rows missing 'customer_id': {e}\")\n",
    "\n",
    "    final_rows = len(df)\n",
    "    logging.info(f\"Transactions cleaned: {initial_rows} -> {final_rows} rows\")\n",
    "    return df\n",
    "\n",
    "def clean_bool_columns(df, bool_columns):\n",
    "    \"\"\"\n",
    "    Convert specified columns to boolean types.\n",
    "    \"\"\"\n",
    "    for col in bool_columns:\n",
    "        if col in df.columns:\n",
    "            try:\n",
    "                df[col] = df[col].astype(bool)\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error converting {col} to bool: {e}\")\n",
    "    return df\n",
    "\n",
    "def clean_kyc_data(df):\n",
    "    \"\"\"\n",
    "    Cleans a KYC DataFrame by:\n",
    "      - Resetting the index so that 'customer_id' becomes a column\n",
    "      - Dropping duplicate rows\n",
    "      - Stripping extra whitespace from string columns\n",
    "      - Converting date columns to datetime\n",
    "      - Converting numeric columns (e.g., 'sales', 'employee_count') to numeric types\n",
    "      - Standardizing geographic and industry code columns to uppercase\n",
    "      - Dropping rows missing 'customer_id'\n",
    "    \"\"\"\n",
    "    initial_rows = len(df)\n",
    "    df = df.copy()\n",
    "    \n",
    "    try:\n",
    "        df.reset_index(inplace=True)\n",
    "        df.drop_duplicates(inplace=True)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error resetting index or dropping duplicates in KYC: {e}\")\n",
    "\n",
    "    try:\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df[col] = df[col].str.strip()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error stripping whitespace in KYC data: {e}\")\n",
    "\n",
    "    try:\n",
    "        if 'established_date' in df.columns:\n",
    "            df['established_date'] = pd.to_datetime(df['established_date'], errors='coerce')\n",
    "        if 'onboard_date' in df.columns:\n",
    "            df['onboard_date'] = pd.to_datetime(df['onboard_date'], errors='coerce')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting date columns in KYC data: {e}\")\n",
    "\n",
    "    try:\n",
    "        if 'sales' in df.columns:\n",
    "            df['sales'] = pd.to_numeric(df['sales'], errors='coerce')\n",
    "        if 'employee_count' in df.columns:\n",
    "            df['employee_count'] = pd.to_numeric(df['employee_count'], errors='coerce')\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error converting numeric columns in KYC data: {e}\")\n",
    "\n",
    "    try:\n",
    "        for col in ['country', 'province', 'city', 'industry_code']:\n",
    "            if col in df.columns:\n",
    "                df[col] = df[col].str.upper()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error standardizing columns in KYC data: {e}\")\n",
    "\n",
    "    try:\n",
    "        df.dropna(subset=['customer_id'], inplace=True)\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error dropping rows with missing customer_id in KYC: {e}\")\n",
    "\n",
    "    final_rows = len(df)\n",
    "    logging.info(f\"KYC data cleaned: {initial_rows} -> {final_rows} rows\")\n",
    "    return df\n",
    "\n",
    "def clean_kyc_industry_codes(df):\n",
    "    \"\"\"\n",
    "    Cleans the KYC industry codes data by:\n",
    "      - Dropping duplicates\n",
    "      - Resetting the index so that 'industry_code' becomes a column\n",
    "      - Stripping whitespace and standardizing to uppercase for all object columns\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = df.copy()\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        df.reset_index(inplace=True)\n",
    "        df.rename(columns={'index': 'industry_code'}, inplace=True)\n",
    "        for col in df.select_dtypes(include=['object']).columns:\n",
    "            df[col] = df[col].str.strip().str.upper()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error cleaning KYC industry codes data: {e}\")\n",
    "    return df\n",
    "\n",
    "def save_cleaned_data(df, filename):\n",
    "    \"\"\"\n",
    "    Saves the given DataFrame to the CLEAN_OUTPUT_DIR with the provided filename.\n",
    "    \"\"\"\n",
    "    output_path = os.path.join(CLEAN_OUTPUT_DIR, filename)\n",
    "    try:\n",
    "        df.to_csv(output_path, index=False)\n",
    "        logging.info(f\"Saved cleaned data to {output_path}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error saving file {filename}: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # List of raw data files to load for transactions\n",
    "    transaction_files = {\n",
    "        \"abm.csv\": None,\n",
    "        \"card.csv\": None,\n",
    "        \"cheque.csv\": None,\n",
    "        \"eft.csv\": None,\n",
    "        \"emt.csv\": None,\n",
    "        \"wire.csv\": None\n",
    "    }\n",
    "\n",
    "    # Load each transaction file if it exists\n",
    "    for file_name in transaction_files.keys():\n",
    "        file_path = os.path.join(RAW_DATA_DIR, file_name)\n",
    "        if file_exists(file_path):\n",
    "            try:\n",
    "                transaction_files[file_name] = pd.read_csv(file_path, index_col=0)\n",
    "                logging.info(f\"Loaded {file_name}\")\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error loading {file_name}: {e}\")\n",
    "                raise\n",
    "        else:\n",
    "            raise FileNotFoundError(f\"{file_path} not found.\")\n",
    "\n",
    "    # Load raw KYC and industry codes data\n",
    "    kyc_file = os.path.join(RAW_DATA_DIR, \"kyc.csv\")\n",
    "    kyc_industry_codes_file = os.path.join(RAW_DATA_DIR, \"kyc_industry_codes.csv\")\n",
    "    if not file_exists(kyc_file) or not file_exists(kyc_industry_codes_file):\n",
    "        raise FileNotFoundError(\"KYC data files not found in the expected directory.\")\n",
    "    try:\n",
    "        kyc_data = pd.read_csv(kyc_file, index_col=0)\n",
    "        kyc_industry_codes = pd.read_csv(kyc_industry_codes_file, index_col=0)\n",
    "        logging.info(\"Loaded KYC data files.\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading KYC data: {e}\")\n",
    "        raise\n",
    "\n",
    "    # Clean transaction data\n",
    "    abm_data = clean_transactions(transaction_files[\"abm.csv\"], date_cols=['transaction_date'], numeric_cols=['amount_cad'])\n",
    "    card_data = clean_transactions(transaction_files[\"card.csv\"], date_cols=['transaction_date'], numeric_cols=['amount_cad'])\n",
    "    cheque_data = clean_transactions(transaction_files[\"cheque.csv\"], date_cols=['transaction_date'], numeric_cols=['amount_cad'])\n",
    "    eft_data = clean_transactions(transaction_files[\"eft.csv\"], date_cols=['transaction_date'], numeric_cols=['amount_cad'])\n",
    "    emt_data = clean_transactions(transaction_files[\"emt.csv\"], date_cols=['transaction_date'], numeric_cols=['amount_cad'])\n",
    "    wire_data = clean_transactions(transaction_files[\"wire.csv\"], date_cols=['transaction_date'], numeric_cols=['amount_cad'])\n",
    "\n",
    "    # Additional enhancement: For card_data, convert negative amounts to absolute values\n",
    "    if 'amount_cad' in card_data.columns:\n",
    "        card_data['amount_cad'] = card_data['amount_cad'].abs()\n",
    "        logging.info(\"Converted negative amounts in card_data to absolute values.\")\n",
    "\n",
    "    # Convert known boolean columns explicitly\n",
    "    abm_data = clean_bool_columns(abm_data, ['cash_indicator'])\n",
    "    card_data = clean_bool_columns(card_data, ['ecommerce_ind'])\n",
    "\n",
    "    # Clean KYC data and industry codes\n",
    "    kyc_data = clean_kyc_data(kyc_data)\n",
    "    kyc_industry_codes = clean_kyc_industry_codes(kyc_industry_codes)\n",
    "\n",
    "    # Save cleaned transaction data\n",
    "    save_cleaned_data(abm_data, \"cleaned_abm.csv\")\n",
    "    save_cleaned_data(card_data, \"cleaned_card.csv\")\n",
    "    save_cleaned_data(cheque_data, \"cleaned_cheque.csv\")\n",
    "    save_cleaned_data(eft_data, \"cleaned_eft.csv\")\n",
    "    save_cleaned_data(emt_data, \"cleaned_emt.csv\")\n",
    "    save_cleaned_data(wire_data, \"cleaned_wire.csv\")\n",
    "\n",
    "    # Save cleaned KYC data and industry codes\n",
    "    save_cleaned_data(kyc_data, \"cleaned_kyc.csv\")\n",
    "    save_cleaned_data(kyc_industry_codes, \"cleaned_kyc_industry_codes.csv\")\n",
    "\n",
    "    logging.info(\"Data cleaning complete. Please review the logs for any issues.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
